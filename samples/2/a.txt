Интеллектуальное сравнение текстов для
поиска плагиата
Тямгин И.А. Белозуб В.А. Аметов О.З.
28 декабря 2014 г.
Аннотация
Целью данной работы было исследование алгоритмов сравнения текстов
для поиска плагиата в русскоязычном тексте и реализация нескольких
из этих алгоритмов. Некоторые из рассмотренных алгоритмов были ре-
ализованы с небольшими изменениями и упрощениями.
Введение
Большие объемы обрабатываемых данных делают задачу поиска похо-
жих текстов алгоритмически сложной. При этом алгоритмы, успешно
работающие для конкретной постановки задачи, бывают неприменимы
или дают плохие результаты для других задач. Так, например, в юри-
слингвистике для определения авторства текста изучают его стилисти-
ческие особенности, категоричность высказываний, использование оце-
ночной лексики. Важно четко определить понятия плагиата и похожих
текстов.
1 Понятие плагиата
Плагиат  умышленное присвоение авторства чужого произведения ис-
кусства или достижения науки, технических решений или изобретений.
Плагиат может быть нарушением авторско-правового законодательства
и патентного законодательства и в качестве таковых может повлечь за
собой юридическую ответственность. С другой стороны, плагиат возмо-
жен и в областях, на которые не распространяется действие каких-либо
1
видов интеллектуальной собственности, например, в математике и дру-
гих фундаментальных научных дисциплинах. [1]
В данной работе будем придерживаться именно этого определения,
поскольку оно в той или иной форме приводится в большинстве статей,
описывающих системы и алгоритмы определения плагиата.
Для разработки алгоритма важно определить два аспекта:
 Критерий определения похожести текстов (форма или содержание)
 Определение оценки степени похожести и ее порогового значения,
до которого тексты не считаются дубликатами.
Согласно классификации, приведенной в [3], случаи плагиата можно
разделить на две основные группы: точное копирование и копирование с
модификацией. Во втором случае текст может быть переформулирован
или переведен на другой язык. Кроме того, может быть скопирован как
целый текст, так и его часть. Алгоритмы, успешно обнаруживающие пла-
гиат одного типа, могут давать очень слабые результаты для плагиата
других типов.
2 Постановка задачи
Целью данной работы является исследование и разработка методов по-
иска плагиата в русскоязычных текстах. Для достижения данной цели
были поставлены следующие задачи:
1. Исследовать существующие методы поиска плагиата.
2. Реализовать систему ставнения текстов, подтверждающую работо-
способность данных методов.
3 Обзор существующих методов
Существует ряд методов для нахождения плагиата в текстах. Наиболее
часто процесс поиска осуществляется по следующему алгоритму:
1. Берут два текста, подозрительные на плагиат.
2. Для этих двух документов анализируется степень сходства с про-
веряемым, если она достаточно высока  предполагается случай
плагиата.
2
3. Пост-обработка. Полученные результаты проверяются, чаще всего
вручную, для исключения ложных обнаружений (например, случа-
ев, когда за плагиат принимается оформленная по всем правилам
цитат).
3.1 Алгоритм шинглов
Одним из наиболее часто используемых является метод ѕшингловї, пред-
ложенный в 1997 году. Он основан на представлении документа в виде
всевозможных последовательностей фиксированной длины k, состоящих
из соседних слов. Такие последовательности назвали ѕшингламиї (от
англ. shingles). Два документа считаются похожими, если множества их
шинглов существенно пересекаются. [2]
Данный подход можно разбить на такие основные этапы:
 канонизация текста
 разбиение на шинглы
 вычисление хэшей шинглов
 сравнение, определение результата
Канонизация текста. Канонизация текста приводит оригинальный
текст к единой нормальной форме. Текст очищается от предлогов, сою-
зов, знаков препинания, HTML тегов, и прочего ненужного ѕмусораї, ко-
торый не должен участвовать в сравнении. В большинстве случаев так-
же предлагается удалять из текста прилагательные, так как они не несут
смысловой нагрузки. Также на этапе канонизации текста можно приво-
дить существительные к именительному падежу, единственному числу,
либо оставлять от них только корни.
Разбиение на шинглы. Шинглы (англ  чешуйки)  выделен-
ные из статьи подпоследовательности слов. Необходимо из сравниваемых
текстов выделить подпоследовательности слов, идущих друг за другом
по k штук (длина шингла). Выборка происходит внахлест, а не встык. Та-
ким образом, разбивая текст на подпоследовательности, мы получим на-
бор шинглов в количестве равному количеству слов минус длина шингла
плюс один.
Вычисление хэшей шинглов. Принцип алгоритма шинглов заклю-
чается в сравнении случайной выборки контрольных сумм шинглов (под-
последовательностей) двух текстов между собой. Проблема алгоритма
заключается в количестве сравнений, ведь это напрямую отражается на
3
производительности. Увеличение количества шинглов для сравнения ха-
рактеризуется экспоненциальным ростом операций, что критически от-
разится на производительности.
3.2 I-Match
Рассмотрим другой сигнатурный подход, основанный уже не на синтак-
сических, а на лексических принципах. Для этого понадобиться понятия
TF и IDF [4].
TF (term frequency  частота слова)  отношение числа вхождения
некоторого слова к общему количеству слов документа. Таким образом,
оценивается важность слова в пределах отдельного документа.
tf(t; d) =
Pni
k nk
(3.1)
где ni есть число вхождений слова в документ, а в знаменателе  общее
число слов в данном документе.
IDF (inverse document frequency  обратная частота документа) 
инверсия частоты, с которой некоторое слово встречается в документах
коллекции. Учјт IDF уменьшает вес широкоупотребительных слов. Для
каждого уникального слова в пределах конкретной коллекции докумен-
тов существует только одно значение IDF
idf(t;D) = log
jDj
j(di  ti)j
(3.2)
где
 |D|  количество документов
 j(di  ti)j -  количество документов, в которых встречается ti.
Выбор основания логарифма в формуле не имеет значения, посколь-
ку изменение основания приводит к изменению веса каждого слова на
постоянный множитель, что не влияет на соотношение весов.
Основная идея этого подхода, описанного в [3], состоит в вычислении
дактилограммы I-Match для представления содержания документов. С
этой целью сначала для исходной коллекции документов строится сло-
варь L, который включает слова со средними значениями IDF. Слова
с большими и маленькими значениями IDF отбрасываются. Затем для
каждого документа формируется множество U различных слов, входя-
щих в него, и определяется пересечение U и словаря L. Если размер это-
го пересечения больше некоторого минимального порога (определяемого
4
экспериментально), то список слов, входящих в пересечение упорядочи-
вается, и для него вычисляется I-Match сигнатура (hash-функция).
Два документа считаются похожими, если у них совпадают I-Match
сигнатуры. Алгоритм имеет высокую вычислительную эффективность,
превосходящую показатели алгоритма шинглов. Другим преимуществом
алгоритма (также, по сравнению с алгоритмом шинглов) является его
высокая эффективность при сравнении небольших по размеру докумен-
тов. Основной недостаток  неустойчивость к небольшим изменениям
содержания документа.
3.3 Слова с оптимальным весом
Алгоритм реализует метод ѕоптимальной поисковой частотыї, предло-
женный М. Масловым, и использующийся для поиска похожих докумен-
тов в широком спектре приложений, от веб-поисковика до кластеризации
новостей. Суть его заключается в следующем. Вместо классической мет-
рики TF  IDF предлагается ее модифицированный вариант.
Вводится эвристическое понятие ѕоптимальной частотыї для слова
равное
ln
10
1000000
= 11:5 (3.3)
Т.е. ѕоптимальнымї считается вхождение слова в 10 документов из 1000000.
Если реальное значение IDF меньше ѕоптимальногої, то оно немного
(по закону параболы) повышается до
IDFopt =
r
IDF
11:5
(3.4)
а если больше, то существенно (как гипербола) снижается до
IDFopt =
11:5
IDF
(3.5)
Таким образом по всей коллекции строится словарь, ставящий каждому
слову в соответствие число документов, в которых оно встречается хотя
бы один раз (df). Далее строится частотный словарь документа и для
каждого слова вычисляется его ѕвесї wt по формуле:
wt = TF  IDFopt (3.6)
TF = 0:5 + 0:5 
tf
tfmax
(3.7)
5
IDF = 􀀀log
tf
N
(3.8)
IDFopt =
p
IDF11:5 (3.9)
если IDF меньше чем 11.5, иначе
IDFopt =
11:5
IDF
(3.10)
Затем выбираются и сцепляются в алфавитном порядке в строку слов
с наибольшими значениями wt.
В качестве сигнатуры документа вычисляется контрольная сумма
CRC32 полученной строки.
3.4 Наиболее часто встречающиеся слова
В качестве сигнатуры документа используется хэш-код строки, полу-
ченной сцеплением k наиболее часто встречающихся в документа слов.
Данный метод можно считать одним из случаев использования анализа
ключевых слов текстов. Несмотря на свою простоту, при использовании
нормализации и стоп-слов метод дает неплохие результаты.
4 Практическая часть
В качестве языка был выбран Python 2.7, являющийся кроссплатфор-
менным языком, подходящим для работы со строками и регулярными
выражениями, а также с протоколом http.
Из перечисленных выше методов выбраны два: алгоритм шинглов и
I-Match.
Программа представляет собой веб-страницу, содержащую 2 тексто-
вых поля ввода для сравниваемых документов, combobox для выбора
длины шингла. Результат работы - вывод документов с выделенными
фрагментами текста, которые присутствуют в обоих документах, кото-
рые показал алгоритм шинглов. Аналогично для I-Match.
Реализацию можно взять из репозитория https://github.com/tyamgin/IPI.git
6
Рис 1. Результат работы алгоритма шинглов
Рис 2. Результат работы алгоритма I-Match
7
5 Заключение
В рамках данной работы были получены следующие результаты:
1. Исследованы существующие методы поиска плагиата.
2. Построена система сравнения двух текстов, реализующая некото-
рые из рассмотренных подходов.
8
Список использованных источников
1. Определение плагиата. https://ru.wikipedia.org/wiki/Плагиат
2. Алгоритм шинглов. https://ru.wikipedia.org/wiki/Алгоритм_шинглов
3. Зеленков Ю.Г., Сегалович И.В. Cравнительный анализ методов опре-
деления нечетких дубликатов для WEB-документов // Труды 9-
ой Всероссийской научной конференции ѕЭлектронные библиоте-
ки: перспективные методы и технологии, электронные коллекцииї
RCDL'2007: Сб. работ участников конкурса, том 1. Переславль-
Залесский, Россия: ѕУниверситет города Переславляї, 2007. С. 166-
174
4. TF-IDF. https://ru.wikipedia.org/wiki/TF-IDF
9